{
  "best_global_step": 7035,
  "best_metric": 0.9451662629376789,
  "best_model_checkpoint": "./models/receipt-ner/checkpoint-7035",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 7035,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07107320540156362,
      "grad_norm": 2.8806824684143066,
      "learning_rate": 4.9296375266524524e-05,
      "loss": 0.1572,
      "step": 100
    },
    {
      "epoch": 0.14214641080312723,
      "grad_norm": 0.42996805906295776,
      "learning_rate": 4.8585643212508886e-05,
      "loss": 0.0817,
      "step": 200
    },
    {
      "epoch": 0.21321961620469082,
      "grad_norm": 0.8247261643409729,
      "learning_rate": 4.787491115849325e-05,
      "loss": 0.0786,
      "step": 300
    },
    {
      "epoch": 0.28429282160625446,
      "grad_norm": 2.195211172103882,
      "learning_rate": 4.716417910447761e-05,
      "loss": 0.0738,
      "step": 400
    },
    {
      "epoch": 0.35536602700781805,
      "grad_norm": 0.9984124302864075,
      "learning_rate": 4.645344705046198e-05,
      "loss": 0.0842,
      "step": 500
    },
    {
      "epoch": 0.42643923240938164,
      "grad_norm": 1.4034475088119507,
      "learning_rate": 4.574271499644634e-05,
      "loss": 0.0692,
      "step": 600
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 3.2678894996643066,
      "learning_rate": 4.5031982942430706e-05,
      "loss": 0.0675,
      "step": 700
    },
    {
      "epoch": 0.5685856432125089,
      "grad_norm": 3.413308620452881,
      "learning_rate": 4.432125088841507e-05,
      "loss": 0.0554,
      "step": 800
    },
    {
      "epoch": 0.6396588486140725,
      "grad_norm": 1.1949212551116943,
      "learning_rate": 4.361051883439943e-05,
      "loss": 0.0591,
      "step": 900
    },
    {
      "epoch": 0.7107320540156361,
      "grad_norm": 3.131850481033325,
      "learning_rate": 4.28997867803838e-05,
      "loss": 0.0607,
      "step": 1000
    },
    {
      "epoch": 0.7818052594171997,
      "grad_norm": 1.781417965888977,
      "learning_rate": 4.218905472636816e-05,
      "loss": 0.0571,
      "step": 1100
    },
    {
      "epoch": 0.8528784648187633,
      "grad_norm": 0.20618802309036255,
      "learning_rate": 4.1478322672352526e-05,
      "loss": 0.0582,
      "step": 1200
    },
    {
      "epoch": 0.923951670220327,
      "grad_norm": 1.8529077768325806,
      "learning_rate": 4.076759061833689e-05,
      "loss": 0.055,
      "step": 1300
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 0.6036182641983032,
      "learning_rate": 4.005685856432125e-05,
      "loss": 0.056,
      "step": 1400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9838324544821411,
      "eval_f1": 0.9267973856209152,
      "eval_loss": 0.05499674007296562,
      "eval_precision": 0.9070362473347549,
      "eval_recall": 0.9474387527839644,
      "eval_runtime": 261.8641,
      "eval_samples_per_second": 9.593,
      "eval_steps_per_second": 0.6,
      "step": 1407
    },
    {
      "epoch": 1.0660980810234542,
      "grad_norm": 5.8608078956604,
      "learning_rate": 3.9346126510305614e-05,
      "loss": 0.036,
      "step": 1500
    },
    {
      "epoch": 1.1371712864250179,
      "grad_norm": 0.44010797142982483,
      "learning_rate": 3.8635394456289984e-05,
      "loss": 0.0343,
      "step": 1600
    },
    {
      "epoch": 1.2082444918265813,
      "grad_norm": 0.7582129240036011,
      "learning_rate": 3.7924662402274347e-05,
      "loss": 0.0382,
      "step": 1700
    },
    {
      "epoch": 1.279317697228145,
      "grad_norm": 0.26162779331207275,
      "learning_rate": 3.721393034825871e-05,
      "loss": 0.0318,
      "step": 1800
    },
    {
      "epoch": 1.3503909026297087,
      "grad_norm": 0.31178414821624756,
      "learning_rate": 3.650319829424307e-05,
      "loss": 0.0333,
      "step": 1900
    },
    {
      "epoch": 1.4214641080312722,
      "grad_norm": 0.3064921796321869,
      "learning_rate": 3.5792466240227435e-05,
      "loss": 0.0387,
      "step": 2000
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 0.150416299700737,
      "learning_rate": 3.5081734186211804e-05,
      "loss": 0.0386,
      "step": 2100
    },
    {
      "epoch": 1.5636105188343994,
      "grad_norm": 0.20540662109851837,
      "learning_rate": 3.437100213219616e-05,
      "loss": 0.0269,
      "step": 2200
    },
    {
      "epoch": 1.634683724235963,
      "grad_norm": 0.5008832216262817,
      "learning_rate": 3.366027007818053e-05,
      "loss": 0.0335,
      "step": 2300
    },
    {
      "epoch": 1.7057569296375266,
      "grad_norm": 1.399656057357788,
      "learning_rate": 3.294953802416489e-05,
      "loss": 0.0324,
      "step": 2400
    },
    {
      "epoch": 1.7768301350390903,
      "grad_norm": 0.8099988698959351,
      "learning_rate": 3.2238805970149255e-05,
      "loss": 0.0345,
      "step": 2500
    },
    {
      "epoch": 1.847903340440654,
      "grad_norm": 1.4442201852798462,
      "learning_rate": 3.1528073916133624e-05,
      "loss": 0.0349,
      "step": 2600
    },
    {
      "epoch": 1.9189765458422174,
      "grad_norm": 0.543494462966919,
      "learning_rate": 3.081734186211798e-05,
      "loss": 0.032,
      "step": 2700
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 1.928911805152893,
      "learning_rate": 3.010660980810235e-05,
      "loss": 0.0388,
      "step": 2800
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9868669784101084,
      "eval_f1": 0.9395002192021044,
      "eval_loss": 0.04500119760632515,
      "eval_precision": 0.9249028916702633,
      "eval_recall": 0.9545657015590201,
      "eval_runtime": 3.9591,
      "eval_samples_per_second": 634.48,
      "eval_steps_per_second": 39.655,
      "step": 2814
    },
    {
      "epoch": 2.061122956645345,
      "grad_norm": 2.532059907913208,
      "learning_rate": 2.939587775408671e-05,
      "loss": 0.0195,
      "step": 2900
    },
    {
      "epoch": 2.1321961620469083,
      "grad_norm": 0.057371046394109726,
      "learning_rate": 2.8685145700071075e-05,
      "loss": 0.0162,
      "step": 3000
    },
    {
      "epoch": 2.203269367448472,
      "grad_norm": 0.013375659473240376,
      "learning_rate": 2.7974413646055437e-05,
      "loss": 0.0186,
      "step": 3100
    },
    {
      "epoch": 2.2743425728500357,
      "grad_norm": 0.2274380475282669,
      "learning_rate": 2.7263681592039803e-05,
      "loss": 0.0128,
      "step": 3200
    },
    {
      "epoch": 2.345415778251599,
      "grad_norm": 0.049029458314180374,
      "learning_rate": 2.655294953802417e-05,
      "loss": 0.0205,
      "step": 3300
    },
    {
      "epoch": 2.4164889836531627,
      "grad_norm": 2.743837594985962,
      "learning_rate": 2.584221748400853e-05,
      "loss": 0.0198,
      "step": 3400
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 3.7568819522857666,
      "learning_rate": 2.5131485429992895e-05,
      "loss": 0.0205,
      "step": 3500
    },
    {
      "epoch": 2.55863539445629,
      "grad_norm": 1.1074162721633911,
      "learning_rate": 2.4420753375977257e-05,
      "loss": 0.0192,
      "step": 3600
    },
    {
      "epoch": 2.6297085998578535,
      "grad_norm": 0.06623651087284088,
      "learning_rate": 2.3710021321961624e-05,
      "loss": 0.0211,
      "step": 3700
    },
    {
      "epoch": 2.7007818052594175,
      "grad_norm": 4.059379577636719,
      "learning_rate": 2.2999289267945986e-05,
      "loss": 0.0214,
      "step": 3800
    },
    {
      "epoch": 2.771855010660981,
      "grad_norm": 1.033677577972412,
      "learning_rate": 2.228855721393035e-05,
      "loss": 0.018,
      "step": 3900
    },
    {
      "epoch": 2.8429282160625444,
      "grad_norm": 1.6572229862213135,
      "learning_rate": 2.1577825159914715e-05,
      "loss": 0.0196,
      "step": 4000
    },
    {
      "epoch": 2.914001421464108,
      "grad_norm": 1.969778299331665,
      "learning_rate": 2.0867093105899078e-05,
      "loss": 0.0166,
      "step": 4100
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 0.8074408769607544,
      "learning_rate": 2.015636105188344e-05,
      "loss": 0.0193,
      "step": 4200
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9870162172918118,
      "eval_f1": 0.9425795053003534,
      "eval_loss": 0.04485921561717987,
      "eval_precision": 0.9347349978098992,
      "eval_recall": 0.9505567928730512,
      "eval_runtime": 3.9575,
      "eval_samples_per_second": 634.739,
      "eval_steps_per_second": 39.671,
      "step": 4221
    },
    {
      "epoch": 3.0561478322672353,
      "grad_norm": 0.10619103908538818,
      "learning_rate": 1.9445628997867803e-05,
      "loss": 0.0115,
      "step": 4300
    },
    {
      "epoch": 3.1272210376687988,
      "grad_norm": 0.615541934967041,
      "learning_rate": 1.873489694385217e-05,
      "loss": 0.0128,
      "step": 4400
    },
    {
      "epoch": 3.1982942430703627,
      "grad_norm": 4.874980449676514,
      "learning_rate": 1.802416488983653e-05,
      "loss": 0.012,
      "step": 4500
    },
    {
      "epoch": 3.269367448471926,
      "grad_norm": 0.06032724305987358,
      "learning_rate": 1.7313432835820898e-05,
      "loss": 0.0089,
      "step": 4600
    },
    {
      "epoch": 3.3404406538734897,
      "grad_norm": 1.7028778791427612,
      "learning_rate": 1.660270078180526e-05,
      "loss": 0.009,
      "step": 4700
    },
    {
      "epoch": 3.411513859275053,
      "grad_norm": 0.033209800720214844,
      "learning_rate": 1.5891968727789623e-05,
      "loss": 0.0087,
      "step": 4800
    },
    {
      "epoch": 3.482587064676617,
      "grad_norm": 1.050583839416504,
      "learning_rate": 1.5181236673773987e-05,
      "loss": 0.0099,
      "step": 4900
    },
    {
      "epoch": 3.5536602700781805,
      "grad_norm": 1.235257625579834,
      "learning_rate": 1.4470504619758352e-05,
      "loss": 0.0092,
      "step": 5000
    },
    {
      "epoch": 3.624733475479744,
      "grad_norm": 3.3803303241729736,
      "learning_rate": 1.3759772565742714e-05,
      "loss": 0.0103,
      "step": 5100
    },
    {
      "epoch": 3.695806680881308,
      "grad_norm": 0.06906721740961075,
      "learning_rate": 1.3049040511727079e-05,
      "loss": 0.0144,
      "step": 5200
    },
    {
      "epoch": 3.7668798862828714,
      "grad_norm": 0.024065503850579262,
      "learning_rate": 1.2338308457711443e-05,
      "loss": 0.0107,
      "step": 5300
    },
    {
      "epoch": 3.837953091684435,
      "grad_norm": 0.027462394908070564,
      "learning_rate": 1.1627576403695807e-05,
      "loss": 0.0077,
      "step": 5400
    },
    {
      "epoch": 3.9090262970859984,
      "grad_norm": 0.576768159866333,
      "learning_rate": 1.091684434968017e-05,
      "loss": 0.0047,
      "step": 5500
    },
    {
      "epoch": 3.9800995024875623,
      "grad_norm": 1.0733082294464111,
      "learning_rate": 1.0206112295664536e-05,
      "loss": 0.0123,
      "step": 5600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9865685006467019,
      "eval_f1": 0.9385056204540445,
      "eval_loss": 0.06040024012327194,
      "eval_precision": 0.9288830715532286,
      "eval_recall": 0.9483296213808463,
      "eval_runtime": 3.9909,
      "eval_samples_per_second": 629.426,
      "eval_steps_per_second": 39.339,
      "step": 5628
    },
    {
      "epoch": 4.051172707889126,
      "grad_norm": 0.005589326377958059,
      "learning_rate": 9.495380241648899e-06,
      "loss": 0.0065,
      "step": 5700
    },
    {
      "epoch": 4.12224591329069,
      "grad_norm": 0.48999732732772827,
      "learning_rate": 8.784648187633263e-06,
      "loss": 0.005,
      "step": 5800
    },
    {
      "epoch": 4.193319118692253,
      "grad_norm": 0.0242460947483778,
      "learning_rate": 8.073916133617626e-06,
      "loss": 0.0048,
      "step": 5900
    },
    {
      "epoch": 4.264392324093817,
      "grad_norm": 0.023487435653805733,
      "learning_rate": 7.363184079601991e-06,
      "loss": 0.0038,
      "step": 6000
    },
    {
      "epoch": 4.33546552949538,
      "grad_norm": 3.3839361667633057,
      "learning_rate": 6.6524520255863545e-06,
      "loss": 0.0045,
      "step": 6100
    },
    {
      "epoch": 4.406538734896944,
      "grad_norm": 0.013831092044711113,
      "learning_rate": 5.941719971570718e-06,
      "loss": 0.0057,
      "step": 6200
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 0.006971949711441994,
      "learning_rate": 5.230987917555082e-06,
      "loss": 0.0045,
      "step": 6300
    },
    {
      "epoch": 4.548685145700071,
      "grad_norm": 0.0045532421208918095,
      "learning_rate": 4.520255863539446e-06,
      "loss": 0.0058,
      "step": 6400
    },
    {
      "epoch": 4.619758351101635,
      "grad_norm": 0.05208031088113785,
      "learning_rate": 3.8095238095238102e-06,
      "loss": 0.0077,
      "step": 6500
    },
    {
      "epoch": 4.690831556503198,
      "grad_norm": 0.01633777841925621,
      "learning_rate": 3.0987917555081737e-06,
      "loss": 0.0062,
      "step": 6600
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.012443823739886284,
      "learning_rate": 2.3880597014925373e-06,
      "loss": 0.0057,
      "step": 6700
    },
    {
      "epoch": 4.832977967306325,
      "grad_norm": 0.06750711798667908,
      "learning_rate": 1.6773276474769014e-06,
      "loss": 0.0044,
      "step": 6800
    },
    {
      "epoch": 4.904051172707889,
      "grad_norm": 0.06149745732545853,
      "learning_rate": 9.665955934612651e-07,
      "loss": 0.005,
      "step": 6900
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.09230673313140869,
      "learning_rate": 2.5586353944562905e-07,
      "loss": 0.0086,
      "step": 7000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9873644413491195,
      "eval_f1": 0.9451662629376789,
      "eval_loss": 0.06642728298902512,
      "eval_precision": 0.9346689895470384,
      "eval_recall": 0.955902004454343,
      "eval_runtime": 4.1486,
      "eval_samples_per_second": 605.511,
      "eval_steps_per_second": 37.844,
      "step": 7035
    }
  ],
  "logging_steps": 100,
  "max_steps": 7035,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1945224960974784.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
