import re
import os
import sqlite3
import asyncio
import logging
from datetime import datetime, timedelta

from aiogram import Bot, Dispatcher, Router, F
from aiogram.types import Message
from transformers import AutoTokenizer, AutoModelForTokenClassification

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TOKEN = os.getenv("BOT_TOKEN")
MODEL_DIR = "model"
DB_PATH = "purchases.db"
MAX_LEN = 128

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–æ—Ç–∞
bot = Bot(token=TOKEN)
dp = Dispatcher()
router = Router()

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ NER
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)
model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)
model.eval()
label_list = ["O", "B", "I"]


def init_db():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–∫—É–ø–∫–∞—Ö"""
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS purchases (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            product TEXT,
            raw_line TEXT,
            ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()
    logger.info("Database initialized.")


init_db()


def clean_text(text, max_digit_len=5):
    """–û—á–∏—Å—Ç–∫–∞ —á–µ–∫–æ–≤"""
    stopwords_set = {
        "—Å—Ç", "—Å–º", "–≥—Ä", "–≥", "–ª", "–º–ª", "–∫–≥", "—à—Ç", "–º–∫–º", "–º", "lm",
    }
    text = text.lower()
    # –£–¥–∞–ª—è–µ–º —Ç–æ—á–∫–∏ –∏ –∑–∞–ø—è—Ç—ã–µ
    text = re.sub(r'[.,]', ' ', text)
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∏—Å–ª–∞
    text = re.sub(r'\d+', ' ', text)
    # –£–¥–∞–ª—è–µ–º —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è (—Å –ø—Ä–æ–±–µ–ª–æ–º –∏ –±–µ–∑)
    units = r"(—Å—Ç|—Å–º|–≥—Ä|–≥|–ª|–º–ª|–∫–≥|—à—Ç|–º–∫–º|–º|lm)"
    text = re.sub(rf"\d+\s?{units}", ' ', text)
    # –£–¥–∞–ª—è–µ–º —Å–∫–æ–±–∫–∏ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    text = re.sub(r'\([^)]*\)|\[[^\]]*\]|\{[^}]*\}', ' ', text)
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    text = re.sub(r'\d+(\.\d+)?%', ' ', text)
    # –£–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'["\'\/¬∞‚Ç¨#$%=]+', ' ', text)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text).strip()

    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
    tokens = text.split()
    # –£–¥–∞–ª—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ü–∏—Ñ—Ä—ã
    tokens = [t for t in tokens if len(t) > 1 and not t.isdigit()]
    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
    if stopwords_set is not None:
        tokens = [t for t in tokens if t not in stopwords_set]
    return tokens


def ner_predict(text: str):
    """–ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —á–µ–∫–µ"""
    encoded = tokenizer(
        text,
        return_offsets_mapping=True,
        return_tensors="pt",
        truncation=True,
        max_length=MAX_LEN
    )

    offsets = encoded["offset_mapping"][0].tolist()
    outputs = model(**{k: v for k, v in encoded.items() if k != "offset_mapping"})
    preds = outputs.logits.argmax(-1)[0].tolist()

    spans = []
    current = None

    for i, p in enumerate(preds):
        start, end = offsets[i]
        if (start, end) == (0, 0):
            continue
        label = label_list[p]

        if label == "B":
            if current:
                spans.append(current)
            current = {"start": start, "end": end}
        elif label == "I" and current:
            current["end"] = end
        else:
            if current:
                spans.append(current)
                current = None

    if current:
        spans.append(current)

    products = []
    for s in spans:
        raw = text[s["start"]:s["end"]].strip().lower()
        tokens = clean_text(raw)
        if tokens:
            products.append(" ".join(tokens))

    if not products:
        tokens = clean_text(text)
        if tokens:
            products.append(" ".join(tokens))

    return products


def log_purchase(user_id: int, product: str, raw_line: str):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫ –≤ –ë–î """
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute(
            "INSERT INTO purchases (user_id, product, raw_line) VALUES (?, ?, ?)",
            (str(user_id), product, raw_line)
        )
        conn.commit()
        conn.close()
        logger.info(f"User {user_id} purchased '{product}' from line '{raw_line}'")
    except Exception as e:
        logger.error(f"Failed to log purchase: {e}")


def get_stats(user_id: int, days: int):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cutoff = datetime.now() - timedelta(days=days)
        cur.execute(
            "SELECT product, COUNT(*) FROM purchases WHERE user_id = ? AND ts > ? GROUP BY product",
            (str(user_id), cutoff)
        )
        rows = cur.fetchall()
        conn.close()
        logger.info(f"Fetched stats for user {user_id} for last {days} days")
        return rows
    except Exception as e:
        logger.error(f"Failed to fetch stats: {e}")
        return []


@router.message(F.text == "/help")
async def cmd_help(msg: Message):
    """/help"""
    logger.info(f"/help requested by user {msg.from_user.id}")
    help_text = (
        "üìù –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ —á–µ–∫–∞ ‚Äî —è –≤—ã–¥–µ–ª—é —Ç–æ–≤–∞—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω—é –∏—Ö.\n"
        "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ Enter.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:\n"
        "/day ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏\n"
        "/week ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é\n"
        "/month ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü"
    )
    await msg.answer(help_text)


@router.message(F.text.startswith("/start"))
async def cmd_start(msg: Message):
    logger.info(f"/start requested by user {msg.from_user.id}")
    await msg.answer("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ —á–µ–∫–∞ ‚Äî —è –≤—ã–¥–µ–ª—é —Ç–æ–≤–∞—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω—é –∏—Ö.\n"
                     "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ Enter.\n\n"
                     "–ö–æ–º–∞–Ω–¥—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:\n"
                     "/day ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏\n"
                     "/week ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é\n"
                     "/month ‚Äî –ø–æ–∫—É–ø–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü\n\n"
                     "/help ‚Äî –ø–æ–º–æ—â—å"
                     )


@router.message(F.text == "/day")
async def cmd_day(msg: Message):
    rows = get_stats(msg.from_user.id, 1)
    if not rows:
        await msg.answer("–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏ –ø–æ–∫—É–ø–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    text = "\n".join(f"{p}: {c} —Ä–∞–∑" for p, c in rows)
    await msg.answer("–ü–æ–∫—É–ø–∫–∏ –∑–∞ –¥–µ–Ω—å:\n" + text)


@router.message(F.text == "/week")
async def cmd_week(msg: Message):
    rows = get_stats(msg.from_user.id, 7)
    if not rows:
        await msg.answer("–ó–∞ –Ω–µ–¥–µ–ª—é –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    text = "\n".join(f"{p}: {c} —Ä–∞–∑" for p, c in rows)
    await msg.answer("–ü–æ–∫—É–ø–∫–∏ –∑–∞ –Ω–µ–¥–µ–ª—é:\n" + text)


@router.message(F.text == "/month")
async def cmd_month(msg: Message):
    rows = get_stats(msg.from_user.id, 30)
    if not rows:
        await msg.answer("–ó–∞ –º–µ—Å—è—Ü –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    text = "\n".join(f"{p}: {c} —Ä–∞–∑" for p, c in rows)
    await msg.answer("–ü–æ–∫—É–ø–∫–∏ –∑–∞ –º–µ—Å—è—Ü:\n" + text)


@router.message(F.text)
async def process_text(msg: Message):
    user_id = msg.from_user.id
    logger.info(f"Received message from user {user_id}: {msg.text}")

    lines = [l.strip() for l in msg.text.split("\n") if l.strip()]
    all_products = []

    for line in lines:
        products = ner_predict(line)
        for p in products:
            log_purchase(user_id, p, line)
            all_products.append(p)

    await msg.answer("–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ:\n" + "\n".join(all_products))


async def main():
    dp.include_router(router)
    logger.info("Bot started polling...")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
